{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOq2jORMPgi9U+H9gt+KjjU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Intertangler/ML4biotech/blob/main/cb206v_exercise6_deepneuralnetworks_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import the data\n",
        "This artificial data represents the gene expression levels (normalized already) of two separate genes. The class labels associated with each data point indicate the presence or absence 1 or 0 of a particular downstream phenotype influenced by the genes. Our goal here is to detect a nonlinear relationship between the two gene expression levels that strongly correlates with the downstream phenotype."
      ],
      "metadata": {
        "id": "nRZguxgF_JLU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYcEXOb-tLIW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/Intertangler/ML4biotech/main/gene_expression_XOR.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "np.random.seed(428)\n",
        "\n",
        "# Shuffle data\n",
        "shuffle_idx = np.random.permutation(len(X))\n",
        "X = X[shuffle_idx]\n",
        "y = y[shuffle_idx]\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Train a logistic regression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "logreg_prob = logreg.predict_proba(X_test)[:, 1]\n",
        "# ROC data for logistic regression\n",
        "logreg_fpr, logreg_tpr, _ = roc_curve(y_test, logreg_prob)\n",
        "logreg_auc = roc_auc_score(y_test, logreg_prob)\n",
        "\n",
        "# Plot data points\n",
        "plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], label=\"Class 0\")\n",
        "plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], label=\"Class 1\")\n",
        "plt.xlabel(\"Gene 1\")\n",
        "plt.ylabel(\"Gene 2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rHeKXSnu6x19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## exercise\n",
        "Complete the missing lines.\n",
        "Use the Keras library to construct a deep neural network - define the model type, its architecture by deciding the number of layers and nodes, the activation function. Compile the model with appropriate loss function, and learning rate scheduling mechanism.\n",
        "\n",
        "The code after this section will then fit the model to the training input and output data. And then a test data set that has been set aside will be used to score the performance with an ROC curve. Compare the performance of your model to a logistic regression. If things have been set up right, the neural network should outperform the logistic regression.\n",
        "\n"
      ],
      "metadata": {
        "id": "njqTB0NY_rVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "\n",
        "\n",
        "#ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ#  # Initialize the model\n",
        "#ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ# # Add one or more hidden layers with a certain number of nodes\n",
        "#ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ# # Add the output layer with a sigmoid activation\n",
        "#ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ# # Compile the model with binary cross-entropy loss and adaptive moment estimation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Function to print the loss every 100 epochs\n",
        "print_callback = LambdaCallback(\n",
        "    on_epoch_end=lambda epoch, logs: print(f\"Epoch {epoch}, Loss: {logs['loss']}\")\n",
        "    if epoch % 100 == 0 else None\n",
        ")\n",
        "\n",
        "# Training part\n",
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=1000,\n",
        "    verbose=0,  # No output\n",
        "    callbacks=[print_callback]  # Print using callback\n",
        ")\n",
        "\n",
        "# predict on test set\n",
        "y_pred_test = model.predict(X_test)\n",
        "mlp_prob_keras = y_pred_test.flatten()\n",
        "#  ROC data\n",
        "keras_mlp_fpr, keras_mlp_tpr, _ = roc_curve(y_test, mlp_prob_keras)\n",
        "keras_mlp_auc = roc_auc_score(y_test, mlp_prob_keras)\n",
        "# plotting part!\n",
        "plt.figure()\n",
        "plt.plot(logreg_fpr, logreg_tpr, label=f'logistic Regression (AUC = {logreg_auc:.2f})')\n",
        "plt.plot(keras_mlp_fpr, keras_mlp_tpr, label=f'Keras MLP (AUC = {keras_mlp_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', label='random performance(AUC = 0.5)')\n",
        "plt.xlabel('false positives ')\n",
        "plt.ylabel('true positives ')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "a-07BC-U63GM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vMUHqtcifGJc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}