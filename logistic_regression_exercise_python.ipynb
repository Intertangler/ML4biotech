{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSMOvSz9ZC/Z8DQB/0drzc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Intertangler/ML4biotech/blob/main/logistic_regression_exercise_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## exercise - logistic regression\n",
        "In this exercise we will look again at simulated data linking blood sugar levels, the pathological occurence of diabetes, and gene expression data for high risk individuals. In contrast to the previous exercise, we will be attempting to construct a classifier using logistic regression that uses the\n",
        "gene expression profiles of individuals to predict whether or not they receive\n",
        "the pathological label."
      ],
      "metadata": {
        "id": "pkRFsezXfH97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "First, let's import some multidimensional data and have a look at it. We will be\n",
        "using dataframes - basically like excel spreadsheets, with columns and rows.\n",
        "Try printing out the dataframe to examine its contents and its header labels.\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/Intertangler/ML4biotech/main/gene_expression_data.csv\"\n",
        "\n",
        "df = pd.read_csv(url) #this line will convert the raw csv file to a pandas \"dataframe\" object, which is a bit like a spreadsheet\n",
        "\n",
        "\n",
        "# Data Preprocessing\n",
        "all_samples = df.iloc[:, :-2].values\n",
        "expression = all_samples\n",
        "genes = expression.shape[1] # Added this line\n",
        "pathological_labels = df['Pathological'].values\n",
        "blood_sugar_levels = df['Blood_Sugar'].values"
      ],
      "metadata": {
        "id": "XNkiLDwx06wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "4g1_xlY8H6lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Next, let's run a visualization of our data. First a matrix displaying genes vs\n",
        "individuals in our dataset, with the brightness of each pixel indicating the\n",
        "expression level. Then we will make a histogram showing the distribution of\n",
        "blood sugar levels in our dataset. In addition, we will color each bar according\n",
        "to the frequency of patients who develop diabetes later in life - the longitudinal\n",
        "part of this data.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from scipy.stats import skewnorm\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.rcParams.update({'font.size': 40})\n",
        "f = plt.figure()\n",
        "f.set_figwidth(12)\n",
        "f.set_figheight(10)\n",
        "sns.heatmap(df.drop(['Pathological', 'Blood_Sugar'], axis=1).T.apply(np.log), cmap=\"Greys\")\n",
        "plt.show()\n",
        "\n",
        "# Create predictors\n",
        "X = all_samples.T\n",
        "\n",
        "# Define the number of bins and get the bin edges\n",
        "num_bins = 50\n",
        "hist, bin_edges = np.histogram(blood_sugar_levels, bins=num_bins)\n",
        "\n",
        "# Calculate the proportion of pathogenic individuals in each bin\n",
        "bin_labels = np.digitize(blood_sugar_levels, bins=bin_edges)\n",
        "proportions = [np.mean(pathological_labels[bin_labels == i]) for i in range(1, len(bin_edges))]\n",
        "\n",
        "# Get a colormap instance and map the proportions to colors\n",
        "cmap = plt.cm.get_cmap('coolwarm')\n",
        "bin_colors = cmap(proportions)\n",
        "\n",
        "# Plotting histogram with color indicating the proportion of pathogenic individuals\n",
        "plt.figure()\n",
        "plt.bar(bin_edges[:-1], hist, width=np.diff(bin_edges), color=bin_colors, edgecolor='white')\n",
        "plt.xlabel('Blood Sugar Levels (mg/dl)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y')\n",
        "plt.colorbar(plt.cm.ScalarMappable(cmap=cmap), label='Diabetes proportion')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H8P3oBuDK6r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## exercise - correlation analysis on the linear regression results\n",
        "Last time we performed linear regression on the data to build a model that can\n",
        "predict the blood sugar levels on the basis of the gene expression profiles of\n",
        "each individual. When we plot the results, we see a visual trend. How does the model perform when we train it on genes with greater or lesser correlation with blood sugar?"
      ],
      "metadata": {
        "id": "kZMpLe1idkOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def calculate_pearson_correlation(x, y):\n",
        "    \"\"\"\n",
        "    Calculate the Pearson correlation coefficient between two arrays.\n",
        "    \"\"\"\n",
        "    # Calculate the means of x and y\n",
        "    #ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ# mean of first variable\n",
        "    #ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ# mean of second variable\n",
        "\n",
        "\n",
        "    # #ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ# Calculate the numerator and the denominator terms for Pearson correlation\n",
        "    #ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ#\n",
        "    #ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ#\n",
        "\n",
        "\n",
        "    # #ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ# Calculate Pearson correlation\n",
        "\n",
        "\n",
        "    return corr\n",
        "\n",
        "high_corr_genes = []\n",
        "low_corr_genes = []\n",
        "genes = expression.shape[1]\n",
        "\n",
        "for i in range(genes):\n",
        "\n",
        "    gene_expression = expression[:, i] # The expression levels of the ith gene for all individuals\n",
        "    corr = calculate_pearson_correlation(blood_sugar_levels, gene_expression) # Calculate the correlation coefficient\n",
        "\n",
        "    if np.abs(corr) > 0.1:  # Check if the correlation is high\n",
        "        high_corr_genes.append(i)\n",
        "    elif np.abs(corr) < 0.05:  # ... or low\n",
        "        low_corr_genes.append(i)\n",
        "\n",
        "high_corr_genes = np.array(high_corr_genes)\n",
        "low_corr_genes = np.array(low_corr_genes)\n",
        "\n",
        "print(f\"Genes with high correlation with blood sugar level: {high_corr_genes}\")\n",
        "print(f\"Genes with low correlation with blood sugar level: {low_corr_genes}\")\n",
        "\n",
        "def fit_normal_equations(X, y):\n",
        "    X_b = np.c_[np.ones((X.shape[0], 1)), X]  # Add a column of ones to X\n",
        "    theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)  # Solve the normal equations\n",
        "    #print(\"Estimated parameters:\")\n",
        "    #print(\"Theta:\")\n",
        "    #print(theta)\n",
        "    return theta\n",
        "\n",
        "def predict_normal(X, theta):\n",
        "    num_samples = X.shape[0]  # Get the number of samples\n",
        "    ones_column = np.ones((num_samples, 1))  # Create a column of ones\n",
        "    X_b = np.c_[ones_column, X]  # Add the column to X\n",
        "    predictions = X_b.dot(theta)  # Calculate the predictions\n",
        "    return predictions\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(expression, blood_sugar_levels, test_size=0.3, random_state=428) #slipt the data into training and test sets\n",
        "\n",
        "# all genes\n",
        "theta_all = fit_normal_equations(X_train, y_train) # Fit the model using normal equations\n",
        "y_pred_all = predict_normal(X_test, theta_all) # make prediction\n",
        "# high correlation genes\n",
        "theta_high = fit_normal_equations(X_train[:, high_corr_genes], y_train)\n",
        "y_pred_high = predict_normal(X_test[:, high_corr_genes], theta_high)\n",
        "# low correlation genses\n",
        "theta_low = fit_normal_equations(X_train[:, low_corr_genes], y_train)\n",
        "y_pred_low = predict_normal(X_test[:, low_corr_genes], theta_low)\n",
        "\n",
        "\n",
        "# plot part\n",
        "plt.figure(figsize=(21, 7))\n",
        "\n",
        "# All genes\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.scatter(y_test, y_pred_all)\n",
        "plt.title('All ')\n",
        "plt.xlabel('Ground Truth')\n",
        "plt.ylabel('Predicted')\n",
        "\n",
        "# High-correlation genes\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.scatter(y_test, y_pred_high)\n",
        "plt.title('High')\n",
        "plt.xlabel('Ground Truth')\n",
        "plt.ylabel('Predicted')\n",
        "\n",
        "# Low-correlation genes\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.scatter(y_test, y_pred_low)\n",
        "plt.title('Low')\n",
        "plt.xlabel('Ground Truth')\n",
        "plt.ylabel('Predicted')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Pm68eLVyl5x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## exercise - logistic regression\n"
      ],
      "metadata": {
        "id": "2a2mfVTikkIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(a):\n",
        "    return 1 / (1 + np.exp(-a))\n",
        "\n",
        "def compute_gradient(X, y, theta):\n",
        "    m = len(y)\n",
        "    h = sigmoid(np.dot(X, theta))\n",
        "    return (1 / m) * np.dot(X.T, (h - y))\n",
        "\n",
        "def compute_nll(y, h):\n",
        "    return -np.mean(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
        "\n",
        "def fit_logistic_regression_with_nll(X, y, lr=0.01, epochs=100000):\n",
        "    X = np.c_[np.ones((X.shape[0], 1)), X]  # Add a column of ones for the bias term\n",
        "    np.random.seed(428)  # Set the seed for reproducibility\n",
        "    theta = np.random.rand(X.shape[1]) * 0.1  # Initialize with small random numbers\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      # update the value of theta with a step computed using the gradient\n",
        "        gradient = #ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ#\n",
        "        theta -= #ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ#\n",
        "\n",
        "        nll = compute_nll(y, sigmoid(np.dot(X, theta)))\n",
        "\n",
        "        if epoch % 1000 == 0:  # Print NLL every 1000 epochs for monitoring\n",
        "            print(f\"Epoch {epoch}, NLL: {nll}\")\n",
        "\n",
        "    return theta\n",
        "\n",
        "\n",
        "def predict_logistic_regression(X, theta):\n",
        "    X = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "    #compute the predicted outcomes by matrix multiplying the data with the params\n",
        "    prob = #ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ#\n",
        "    return prob, (prob > 0.5).astype(int)\n",
        "\n",
        "\n",
        "# Data sets: [(subset, title)]\n",
        "data_sets = [\n",
        "    (expression, 'All Genes'),\n",
        "    (expression[:, high_corr_genes], 'High-Correlation Genes'),\n",
        "    (expression[:, low_corr_genes], 'Low-Correlation Genes')\n",
        "]\n",
        "\n",
        "# Loop through data subsets\n",
        "for data, title in data_sets:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data, pathological_labels, test_size=0.3, random_state=1234)\n",
        "\n",
        "    # Fit the model\n",
        "    theta = fit_logistic_regression_with_nll(X_train, y_train, lr=.0001, epochs=50000)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_proba, y_pred = predict_logistic_regression(X_test, theta)\n",
        "\n",
        "    print(\"Predicted probabilities:\", y_pred_proba)\n",
        "    print(\"Predicted labels:\", y_pred)\n",
        "    print(\"Model Coefficients:\", theta[1:])\n",
        "    print(\"Model Intercept:\", theta[0])\n",
        "\n",
        "    # ROC curve and AUC\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Other metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    conf_mat = confusion_matrix(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    logit_values = np.dot(X_test, theta[1:].T) + theta[0]  # Calculate the logit values (linear combination of weights and features)\n",
        "\n",
        "    # Create scatter plot with line plot of sigmoidal function\n",
        "    plt.figure(figsize=(24, 6))\n",
        "    plt.scatter(logit_values, y_pred_proba, c=y_test, cmap=\"bwr\", alpha=0.7, s=5 )\n",
        "    plt.plot(np.arange(-10, 10, 0.1), 1 / (1 + np.exp(-np.arange(-10, 10, 0.1))), c=\"grey\", lw=0.3)\n",
        "    plt.xlabel(\"Logit\")\n",
        "    plt.ylabel(\"Probability\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "    # Plot ROC curve\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'area under curve = {roc_auc:.2f}')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve for {title}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    print(f'Accuracy for {title}: {accuracy}')\n",
        "    print(f'Confusion Matrix for {title}:\\n{conf_mat}')\n",
        "    print(f'F1 Score for {title}: {f1}\\n')\n"
      ],
      "metadata": {
        "id": "DxG-4TBHLF6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### extra - logistic regression with blood sugar for comparison"
      ],
      "metadata": {
        "id": "D8TGgzjEsHId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blood_sugar_data = df[['Blood_Sugar']].values  # Make sure it's a 2D array\n",
        "pathological_labels = df['Pathological'].values\n",
        "\n",
        "blood_sugar_data_set = [(blood_sugar_data, 'Blood Sugar Levels')]\n",
        "\n",
        "for data, title in blood_sugar_data_set:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data, pathological_labels, test_size=0.3, random_state=1234)\n",
        "\n",
        "    theta = fit_logistic_regression_with_nll(X_train, y_train, lr=0.01, epochs=50000)\n",
        "    y_pred_proba, y_pred = predict_logistic_regression(X_test, theta)\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    conf_mat = confusion_matrix(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    logit_values = np.dot(X_test, theta[1:].T) + theta[0]\n",
        "\n",
        "    plt.figure(figsize=(24, 6))\n",
        "    plt.scatter(logit_values, y_pred_proba, c=y_test, cmap=\"bwr\", alpha=0.7, s=5)\n",
        "    plt.plot(np.arange(-10, 10, 0.1), 1 / (1 + np.exp(-np.arange(-10, 10, 0.1))), c=\"grey\", lw=0.3)\n",
        "    plt.xlabel(\"Logit\")\n",
        "    plt.ylabel(\"Probability\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve for {title}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    print(f'Accuracy for {title}: {accuracy}')\n",
        "    print(f'Confusion Matrix for {title}:\\n{conf_mat}')\n",
        "    print(f'F1 Score for {title}: {f1}\\n')\n"
      ],
      "metadata": {
        "id": "MVbKVFqgQwOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5kBHcsLqtp5a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}