{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvB9+7YzmrdXtuFepkpbpI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Intertangler/ML4biotech/blob/main/cb206v_exercise4_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## exercise - linear regression\n",
        "The dataset in this exercise was generated to simulate a large study in which many individuals have both a gene expression profile (multiple gene expression levels) linked to measurements of their blood sugar level, and then as a longitudinal study, those individuals who later develop diabetes are recorded (this is a high-risk group, let's say). The data has been engineered to contain some interesting structure which we will explore over the next few lessons. For today though, our task is to establish a model to predict the blood sugar concentration from the expression data using multivariate linear regression."
      ],
      "metadata": {
        "id": "pkRFsezXfH97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "First, let's import some multidimensional data and have a look at it. We will be\n",
        "using dataframes - basically like excel spreadsheets, with columns and rows.\n",
        "Try printing out the dataframe to examine its contents and its header labels.\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/Intertangler/ML4biotech/main/gene_profile_blood_sugar_diabetes_data.csv\"\n",
        "\n",
        "df = pd.read_csv(url) #this line will convert the raw csv file to a pandas \"dataframe\" object, which is a bit like a spreadsheet\n",
        "\n",
        "\n",
        "all_samples = df.iloc[:, :-2].T.values\n",
        "Pathological = df['Pathogenic_Label'].values\n",
        "blood_sugar_levels = df['Blood_Sugar'].values"
      ],
      "metadata": {
        "id": "XNkiLDwx06wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "have a look at the dataset\n",
        "\"\"\"\n",
        "df"
      ],
      "metadata": {
        "id": "BAOis2bOn1cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Next, let's run a visualization of our data. First a matrix displaying genes vs\n",
        "individuals in our dataset, with the brightness of each pixel indicating the\n",
        "expression level. Then we will make a histogram showing the distribution of\n",
        "blood sugar levels in our dataset. In addition, we will color each bar according\n",
        "to the frequency of patients who develop diabetes later in life - the longitudinal\n",
        "part of this data.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from scipy.stats import skewnorm\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.rcParams.update({'font.size': 40})\n",
        "f = plt.figure()\n",
        "f.set_figwidth(12)\n",
        "f.set_figheight(10)\n",
        "sns.heatmap(df.drop(['Pathogenic_Label', 'Blood_Sugar'], axis=1).T.apply(np.log), cmap=\"Greys\")\n",
        "plt.show()\n",
        "\n",
        "# Create predictors\n",
        "X = all_samples.T\n",
        "\n",
        "# Define the number of bins and get the bin edges\n",
        "num_bins = 50\n",
        "hist, bin_edges = np.histogram(blood_sugar_levels, bins=num_bins)\n",
        "\n",
        "# Calculate the proportion of pathogenic individuals in each bin\n",
        "bin_labels = np.digitize(blood_sugar_levels, bins=bin_edges)\n",
        "proportions = [np.mean(Pathological[bin_labels == i]) for i in range(1, len(bin_edges))]\n",
        "\n",
        "# Get a colormap instance and map the proportions to colors\n",
        "cmap = plt.cm.get_cmap('coolwarm')\n",
        "bin_colors = cmap(proportions)\n",
        "\n",
        "# Plotting histogram with color indicating the proportion of pathogenic individuals\n",
        "plt.figure()\n",
        "plt.bar(bin_edges[:-1], hist, width=np.diff(bin_edges), color=bin_colors, edgecolor='white')\n",
        "plt.xlabel('Blood Sugar Levels (mg/dl)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y')\n",
        "plt.colorbar(plt.cm.ScalarMappable(cmap=cmap), label='Diabetes proportion')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H8P3oBuDK6r6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Use this guide to help you complete the linear algebra functions needed to do the\n",
        "normal equations part of the next section\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "# Define a 3x2 matrix and a 2x2 matrix for matmul operations\n",
        "Matrix1 = np.array([[1, 2], [3, 4], [5, 6]])  # 3x2 matrix\n",
        "Matrix2 = np.array([[7, 8], [9, 10]])         # 2x2 matrix\n",
        "Vector = np.array([11, 12])                   # 1x2 vector\n",
        "Vector1 = np.array([1, 2, 3])                 # 3-element vector for dot product\n",
        "Vector2 = np.array([4, 5, 6])                 # 3-element vector for dot product\n",
        "\n",
        "# Matrix multiplication of two matrices using matmul\n",
        "matmul_matrices = np.matmul(Matrix1, Matrix2)\n",
        "print(\"\\nMatrix Multiplication of Matrix1 (3x2) and Matrix2 (2x2):\\n\", matmul_matrices)\n",
        "\n",
        "# Matrix-vector multiplication using matmul\n",
        "matmul_matrix_vector = np.matmul(Matrix1, Vector)\n",
        "print(\"\\nMatrix-Vector Multiplication of Matrix1 (3x2) and Vector (2-element):\\n\", matmul_matrix_vector)\n",
        "\n",
        "# Transpose of Matrix1\n",
        "transpose_Matrix1 = np.transpose(Matrix1)\n",
        "print(\"\\nTranspose of Matrix1 (3x2):\\n\", transpose_Matrix1)\n",
        "\n",
        "# Inverse of a 2x2 matrix (for example purposes, using Matrix2)\n",
        "inverse_Matrix2 = np.linalg.inv(Matrix2)\n",
        "print(\"\\nInverse of Matrix2 (2x2):\\n\", inverse_Matrix2)\n"
      ],
      "metadata": {
        "id": "cPoOsNFu_WZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### complete the missing lines below to perform linear regression and predict blood sugar level on the basis of individuals' gene expression profile"
      ],
      "metadata": {
        "id": "f6vYHyj7FTBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def fit_normal_equations(X, y):\n",
        "    # Add a column of ones to X, this will be for the intercept values\n",
        "    X = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "\n",
        "\n",
        "#ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ## Step 1: Compute X^T (transpose of X)\n",
        "#ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ## Step 2: Compute X^T * X (matrix multiplication)\n",
        "#ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ## Step 3: Compute the inverse of (X^T * X)\n",
        "#ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ## Step 4: Compute X^T * y (matrix multiplication)\n",
        "#ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ#  theta = (X^T * X)^âˆ’1*X^T*y Solve the normal equations\n",
        "\n",
        "    print(\"Estimated parameters:\")\n",
        "    print(\"Theta:\")\n",
        "    print(theta)\n",
        "\n",
        "    return theta\n",
        "\n",
        "\n",
        "\n",
        "def predict_normal(X, theta):\n",
        "\n",
        "    num_samples = X.shape[0] # Get number of samples in the dataset\n",
        "    ones_column = np.ones((num_samples, 1)) # Create array of ones with the same number of rows as X\n",
        "\n",
        "    # Add a column of ones to the start of X to account for the intercept term\n",
        "    # This is often denoted as X_b where 'b' stands for bias (or intercept)\n",
        "    X_b = np.c_[ones_column, X]\n",
        "\n",
        "    # Now we calculate the predictions using the formula:\n",
        "    # predictions = X_b . theta\n",
        "    # The dot product of X_b and theta gives us the predicted values\n",
        "    predictions = np.matmul(X_b,theta)\n",
        "    return predictions\n",
        "\n",
        "X = all_samples.T\n",
        "y = blood_sugar_levels\n",
        "\n",
        "# Split data into training and test subsets. Use the train_test_split() function\n",
        "#ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ YOUR CODE HERE ðŸŒŸðŸŒŸðŸŒŸðŸŒŸ# X_train, X_test, y_train, y_test =\n",
        "\n",
        "# Train model using  normal equations\n",
        "theta = fit_normal_equations(X_train, y_train)\n",
        "\n",
        "# predictions on the test set\n",
        "y_pred = predict_normal(X_test, theta)\n",
        "\n",
        "# rss\n",
        "rss = np.sum((y_test - y_pred)**2)\n",
        "\n",
        "# r-squared value\n",
        "tss = np.sum((y_test - np.mean(y_test))**2)\n",
        "r2 = 1 - (rss / tss)\n",
        "\n",
        "print(f'Residual Sum of Squares: {rss}')\n",
        "print(f'R-squared: {r2}')\n",
        "\n",
        "# Plot true vs predicted\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('True Blood Sugar Level (mg/dl)')\n",
        "plt.ylabel('Predicted (mg/dl)')\n",
        "plt.title('True vs Predicted Blood Sugar Levels')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RzPo1w-mr_v3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## extra - doing linear regression with MLE by iterative gradient descent"
      ],
      "metadata": {
        "id": "KqZQEjlUtfxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def fit_mle(X, y):\n",
        "    m = len(y)\n",
        "    X_b = np.c_[np.ones((m, 1)), X]\n",
        "\n",
        "    def neg_log_likelihood(params):\n",
        "        theta = params[:-1].reshape(-1, 1)\n",
        "        sigma_squared = params[-1]\n",
        "\n",
        "        if sigma_squared <= 0:\n",
        "            return np.inf  # Return a large value to indicate that sigma_squared must be positive\n",
        "\n",
        "        residuals = y.reshape(-1, 1) - X_b.dot(theta)\n",
        "        ll = -0.5 * m * np.log(2 * np.pi * sigma_squared) - (1/(2 * sigma_squared)) * np.sum(residuals ** 2)\n",
        "        return -ll\n",
        "\n",
        "    # Initial guess\n",
        "    init_params = np.zeros(X_b.shape[1] + 1)\n",
        "    init_params[-1] = 1  # Initial guess for sigma_squared\n",
        "\n",
        "    # Optimize the nll function\n",
        "    result = minimize(neg_log_likelihood, init_params)\n",
        "\n",
        "    # Extratc parameters\n",
        "    theta = result.x[:-1].reshape(-1, 1)\n",
        "    sigma_squared_estimated = result.x[-1]\n",
        "\n",
        "    print(\"Estimated parameters:\")\n",
        "    print(\"Theta:\", theta)\n",
        "    print(\"Sigma squared:\", sigma_squared_estimated)\n",
        "\n",
        "    return theta, sigma_squared_estimated\n",
        "\n",
        "\n",
        "    return theta, history\n",
        "\n",
        "def predict(X, theta):\n",
        "    X_b = np.c_[np.ones((len(X), 1)), X]\n",
        "    return X_b.dot(theta)\n",
        "\n",
        "#  predictors\n",
        "X = all_samples.T\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, blood_sugar_levels, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the model with MLE\n",
        "theta, sigma_squared_estimated = fit_mle(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = predict(X_test_scaled, theta).flatten()\n",
        "\n",
        "# Calculate Residual Sum of Squares\n",
        "rss = ((y_test - y_pred) ** 2).sum()\n",
        "\n",
        "# the R-squared value\n",
        "tss = ((y_test - y_test.mean()) ** 2).sum()\n",
        "r2 = 1 - (rss / tss)\n",
        "\n",
        "print(f'Residual Sum of Squares: {rss}')\n",
        "print(f'R-squared: {r2}')\n",
        "\n",
        "# Plot true vs predicted\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.ylabel('Predicted (mg/dl)')\n",
        "plt.xlabel('True Blood Sugar Level (mg/dl)')\n",
        "plt.title('True vs Predicted Blood Sugar Levels')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0nVRdeqslHQ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}